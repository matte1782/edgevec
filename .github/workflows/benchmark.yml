# EdgeVec Performance Benchmarks CI
# Tracks P50 and tail latency and detects regressions
# Created: W14.2 (Dec 2025)
# Revised: W14.1 Day 1 - Fixed path alignment with check_regression.py
# Revised: W18.3 v1.3 - Calibrated baselines, tail (not P99) naming, optimized workflow

name: Performance Benchmarks

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  # Override .cargo/config.toml's target-cpu=native to prevent SIGILL on CI runners
  # CI runners have varying CPU capabilities, so we use x86-64-v3 (AVX2) as baseline
  RUSTFLAGS: "-C target-cpu=x86-64-v3 -C opt-level=3"

jobs:
  benchmark:
    name: Performance Regression Check
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-registry-

      # Do NOT cache target/ to avoid SIGILL from CPU-specific artifacts
      - name: Clean build artifacts
        run: cargo clean || true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run validation benchmarks
        run: |
          # Run the validation benchmark suite which outputs to target/criterion/validation/
          # This matches the path expected by check_regression.py
          # Benchmarks: insert_1k, search_10k, quantization_encode, hamming_distance
          cargo bench --bench validation -- --noplot

      # [m2 FIX] Run check once and capture both stdout and PR comment in single pass
      - name: Check for regressions and generate report
        id: regression_check
        run: |
          # Run regression check and save output
          python benches/check_regression.py 2>&1 | tee regression_output.txt
          RESULT=${PIPESTATUS[0]}

          # Generate PR comment if on pull request
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            python benches/check_regression.py --pr-comment > benchmark_comment.md
          fi

          # Exit with original result
          exit $RESULT
        continue-on-error: false

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results-${{ github.sha }}
          path: |
            target/criterion/
            benches/baselines.json
            regression_output.txt
          retention-days: 30

      - name: Comment on PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let summary;
            try {
              summary = fs.readFileSync('benchmark_comment.md', 'utf8');
            } catch (e) {
              summary = '## Benchmark Results\n\n';
              summary += '| Benchmark | Status |\n';
              summary += '|:----------|:-------|\n';
              summary += '| insert_1k | ✅ Completed |\n';
              summary += '| search_10k | ✅ Completed |\n';
              summary += '| quantization_encode | ✅ Completed |\n';
              summary += '| hamming_distance | ✅ Completed |\n\n';
              summary += 'See artifacts for detailed Criterion reports.';
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
